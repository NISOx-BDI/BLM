{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FS_sandbox.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomMaullin/BLM/blob/master/FS_sandbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIMtrhFKB3Ay",
        "colab_type": "text"
      },
      "source": [
        "# FS implementation in python\n",
        "\n",
        "This code implements the Fisher Scoring algorithm for estimating the parameters of linear mixed effects models as described in [Demidenko 2013](https://www.wiley.com/en-us/Mixed+Models%3A+Theory+and+Applications+with+R%2C+2nd+Edition-p-9781118091579)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNFQ0-MpQuBm",
        "colab_type": "text"
      },
      "source": [
        "## Pip Installations\n",
        "\n",
        "Pip install everything."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX02P0KvBWJr",
        "colab_type": "code",
        "outputId": "a1816f1b-29a3-4829-f5b5-7e739b395429",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install scipy\n",
        "!pip install matplotlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.24.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.16.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.16.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.0.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.16.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (41.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4JYRICVBtjl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Python Imports\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkTBWbRKQ5ah",
        "colab_type": "text"
      },
      "source": [
        "We need:\n",
        " - `numpy` for matrix handling.\n",
        " - `scipy` for sparse matrix functions.\n",
        " - `pandas` for quick reading and writing of csv files.\n",
        " - `os` and `sys` for basic commandline functions\n",
        " - `time` for timing functions.\n",
        " - `matplotlib` for making displays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tebSlxvBBruv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cvxopt\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import scipy.sparse\n",
        "import scipy.sparse.linalg\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS5zhoWCDZ8E",
        "colab_type": "text"
      },
      "source": [
        "## Toy Dataset\n",
        "\n",
        "This section read ins and formats a toy dataset. The files used here were generated in `R` and with **True** values (those with postfix `True`) being those used to generate the data and **Estimated** (those with postfix `REst`) values being the estimates `R`'s `lmer` package generated from this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy39zwuhkn4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a data directory\n",
        "if not os.path.isdir('/Data'):\n",
        "  os.mkdir('/Data')\n",
        "  \n",
        "os.chdir('/Data')\n",
        "\n",
        "# Clone small git repo containg some csv files.\n",
        "if not os.path.isdir('/Data/BLMM-testdata'):\n",
        "  !git clone https://github.com/TomMaullin/BLMM-testdata.git\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EWsCZjCQcc9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Z matrix\n",
        "\n",
        "The below reads in Z and makes an image of Z transpose.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoKOwHqcEKDT",
        "colab_type": "code",
        "outputId": "04226a12-cddc-40c0-dc69-81b9a86324fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# Read in random effects design matrix and convert it into it's sparse format in\n",
        "# cvxopt.\n",
        "Z_3col=pd.read_csv('/Data/BLMM-testdata/Z_3col.csv',header=None).values\n",
        "Z = scipy.sparse.csr_matrix((Z_3col[:,2].tolist(), \\\n",
        "                            ((Z_3col[:,0]-1).astype(np.int64), \\\n",
        "                             (Z_3col[:,1]-1).astype(np.int64))))\n",
        "\n",
        "# Create an image of Z'\n",
        "imshow(Z.toarray().transpose(), \\\n",
        "       interpolation='nearest', vmin=-5, vmax=5, aspect='auto')\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9c990f6470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAgIQR8AAkLQB4CAEPQBICD/D6dLkr+Yz5X4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkd2LdwKLWtP",
        "colab_type": "text"
      },
      "source": [
        "### Estimated Random Effects matrix\n",
        "\n",
        "The below reads in the Random effects variance predicted by `R`'s `lmer`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOqQRAROqdkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in estimated variance\n",
        "RFXVar_REst = pd.read_csv('/Data/BLMM-testdata/estd_rfxvar.csv',header=None).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RStOLwF_LlTE",
        "colab_type": "text"
      },
      "source": [
        "### Y vector\n",
        "\n",
        "The response vector is read in here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG8eWNdpPQOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=pd.read_csv('/Data/BLMM-testdata/Y.csv',header=None).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHm6DjdbPTvg",
        "colab_type": "text"
      },
      "source": [
        "### X matrix\n",
        "\n",
        "The fixed effects design matrix is read in here. It consists of an intercept and two random (Gaussian) columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqTKH4n_Po8e",
        "colab_type": "code",
        "outputId": "728be601-e935-422a-cf14-096b989c29e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "X=pd.read_csv('/Data/BLMM-testdata/X.csv',header=None).values\n",
        "\n",
        "# Image of the first 20 rows of X\n",
        "imshow(X[1:20,:])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9c958853c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFYAAAD8CAYAAADt0VN/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_sXGD8qzskp",
        "colab_type": "text"
      },
      "source": [
        "### Number of Levels and Parameters\n",
        "\n",
        "The number of levels is given by a vector with one entry for each grouping factor. e.g. nlevels=[10,2] means there are 10 levels for factor 1 and 2 levels for factor 2. \n",
        "\n",
        "The number of parameters is given by a vector with one entry for each grouping factor. e.g. nparams=[3,4] means there are 3 variables for factor 1 and 4 variables for factor 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e5bUA2DztCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlevels = np.array([20,3])\n",
        "nparams = np.array([2,2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0byKXygpCa1P",
        "colab_type": "text"
      },
      "source": [
        "### True b values\n",
        "\n",
        "The true recorded values of the random effects b vector in this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzwuuWSdCbCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b_True=pd.read_csv('/Data/BLMM-testdata/true_b.csv',header=None).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvfns6c-CbPd",
        "colab_type": "text"
      },
      "source": [
        "### True beta values\n",
        "\n",
        "The true fixed effects parameters used to generate this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlvolWwvCbbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beta_True=pd.read_csv('/Data/BLMM-testdata/true_beta.csv',header=None).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVyBWvQK2Gw5",
        "colab_type": "text"
      },
      "source": [
        "### Product Matrices\n",
        "\n",
        "All products of matrices are calculated beforehand as it is both more computationally efficient and also similar to the setting we are interested in. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e53HYCsj2G7I",
        "colab_type": "code",
        "outputId": "47c5b434-d62a-4cb5-eee0-af7346f3f42c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Z transpose Z\n",
        "print(Z.shape)\n",
        "ZtZ = np.matmul(Z.toarray().transpose(),Z.toarray()) # This works for products involving sparse\n",
        "# Sparse \n",
        "# ZtZ = Z.transpose() * Z\n",
        "\n",
        "# Z transpose X\n",
        "XtZ = np.matmul(X.transpose(),Z.toarray())\n",
        "\n",
        "# X transpose Z\n",
        "ZtX = np.matmul(Z.toarray().transpose(),X)\n",
        "\n",
        "# ZtY\n",
        "ZtY = np.matmul(Z.toarray().transpose(),Y)\n",
        "\n",
        "# YtZ\n",
        "YtZ = np.matmul(Y.transpose(),Z.toarray())\n",
        "\n",
        "# XtX\n",
        "XtX = np.matmul(X.transpose(),X)\n",
        "\n",
        "# XtY\n",
        "XtY = np.matmul(X.transpose(),Y)\n",
        "\n",
        "# YtX\n",
        "YtX = np.matmul(Y.transpose(),X)\n",
        "\n",
        "# YtX\n",
        "YtY = np.matmul(Y.transpose(),Y)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilAB3qmDMHa8",
        "colab_type": "text"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "This section contains miscellaneous functions used to help the `FS` function including functions to work out the duplication matrix.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVkJVMSo1fCF",
        "colab_type": "text"
      },
      "source": [
        "###Matrix to Vector function\n",
        "\n",
        "This function takes in a matrix and vectorizes it (i.e. transforms it to a vector of each of the columns of the matrix stacked on top of one another). Example:\n",
        "\n",
        "$$\\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\\\\\end{bmatrix} \\rightarrow \\begin{bmatrix} a \\\\ d \\\\ g \\\\ b \\\\ e \\\\ h \\\\ c \\\\ f \\\\ i \\end{bmatrix}$$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBhQXRF01d9n",
        "colab_type": "code",
        "outputId": "cc85ce8c-6e5b-4fab-fea0-9bdc029091a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "source": [
        "def mat2vec(matrix):\n",
        "  \n",
        "  #Return vectorised matrix\n",
        "  return(matrix.transpose().reshape(matrix.shape[0]*matrix.shape[1],1))\n",
        "\n",
        "# Example:\n",
        "matrix = np.random.randn(3,3)\n",
        "print(matrix)\n",
        "print(mat2vec(matrix))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.33645474  0.75002691 -0.70761799]\n",
            " [ 0.42421574 -0.19594959 -1.33833766]\n",
            " [-0.87467645  0.40083259  0.08095597]]\n",
            "[[ 0.33645474]\n",
            " [ 0.42421574]\n",
            " [-0.87467645]\n",
            " [ 0.75002691]\n",
            " [-0.19594959]\n",
            " [ 0.40083259]\n",
            " [-0.70761799]\n",
            " [-1.33833766]\n",
            " [ 0.08095597]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcIJAyHi1eTj",
        "colab_type": "text"
      },
      "source": [
        "###Matrix to Vector function\n",
        "\n",
        "This function takes in a (symmetric, square) matrix and half-vectorizes it (i.e. transforms it to a vector of each of the columns of the matrix, below and including the diagonal, stacked on top of one another). Example:\n",
        "\n",
        "$$\\begin{bmatrix} a & b & c \\\\ b & d & e \\\\ c & e & f \\\\\\end{bmatrix} \\rightarrow \\begin{bmatrix} a \\\\ b \\\\ c \\\\ d \\\\ e \\\\ f \\end{bmatrix}$$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fpQzdwA3QGq",
        "colab_type": "code",
        "outputId": "53b2f9e8-ae72-4d2c-8131-d901cf41aaad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "def mat2vech(matrix):\n",
        "  \n",
        "  # Get lower triangular indices\n",
        "  rowinds, colinds = np.tril_indices(matrix.shape[0]) #Try mat.transpose()[trilu]?\n",
        "  \n",
        "  # They're in the wrong order so we need to order them\n",
        "  # To do this we first hash them\n",
        "  indhash = colinds*matrix.shape[0]+rowinds\n",
        "  \n",
        "  # Sort permutation\n",
        "  perm=np.argsort(indhash)\n",
        "  \n",
        "  # Return vectorised half-matrix\n",
        "  return(np.array([matrix[rowinds[perm],colinds[perm]]]).transpose())\n",
        "\n",
        "# Example:\n",
        "matrix = np.random.randn(3,3)\n",
        "print(matrix*matrix.transpose())\n",
        "print(mat2vech(matrix*matrix.transpose()))\n",
        "\n",
        "#print(vech2mat(invDupMat(3) @ mat2vec(matrix*matrix.transpose())))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.04525747 2.95716647 1.8114078 ]\n",
            " [2.95716647 1.89084746 0.74736483]\n",
            " [1.8114078  0.74736483 0.04026532]]\n",
            "[[0.04525747]\n",
            " [2.95716647]\n",
            " [1.8114078 ]\n",
            " [1.89084746]\n",
            " [0.74736483]\n",
            " [0.04026532]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V79rfwHp9eNe",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DmbjUOh9euy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vec2mat(vec):\n",
        "  \n",
        "  # Return matrix\n",
        "  return(vec.reshape(np.int64(np.sqrt(vec.shape[0])),np.int64(np.sqrt(vec.shape[0]))).transpose())\n",
        "\n",
        "# Example\n",
        "#vec = np.array([[1,2,3,4]]).transpose()\n",
        "#mat = vec2mat(vec)\n",
        "#print(vec)\n",
        "#print(mat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijBvOZsu9iKg",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhitZciM9hcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vech2mat(vech):\n",
        "  \n",
        "  # dimension of matrix\n",
        "  n = np.int64((-1+np.sqrt(1+8*vech.shape[0]))/2)\n",
        "  matrix = np.zeros((n,n))\n",
        "  \n",
        "  # Get lower triangular indices\n",
        "  rowinds, colinds = np.tril_indices(matrix.shape[0])\n",
        "  \n",
        "  # They're in the wrong order so we need to order them\n",
        "  # To do this we first hash them\n",
        "  indhash = colinds*matrix.shape[0]+rowinds\n",
        "  \n",
        "  # Sort permutation\n",
        "  perm=np.argsort(indhash)\n",
        "  \n",
        "  # Assign values to lower half\n",
        "  matrix[rowinds[perm],colinds[perm]] = vech.reshape(vech.shape[0])\n",
        "  \n",
        "  # Assign values to upper half\n",
        "  matrix[colinds[perm],rowinds[perm]] = vech.reshape(vech.shape[0])\n",
        "  \n",
        "  # Return vectorised half-matrix\n",
        "  return(matrix)\n",
        "\n",
        "# Example:\n",
        "#vech = np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]])\n",
        "#matrix = vech2mat(vech)\n",
        "#print(vech)\n",
        "#print(matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd3_jaDe-MNy",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qutTs-8S-MuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vec2vech(vec):\n",
        "  \n",
        "  # Return vech\n",
        "  return(mat2vech(vec2mat(vec)))\n",
        "\n",
        "# Example\n",
        "#vec = np.array([[1],[2],[3],[2],[4],[5],[3],[5],[6]])\n",
        "#vech = vec2vech(vec)\n",
        "\n",
        "#print(vec)\n",
        "#print(vech)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-Yp9RjT-PmL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8txTVtu-Pwc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vech2vec(vech):\n",
        "  \n",
        "  # Return vec\n",
        "  return(mat2vec(vech2mat(vech)))\n",
        "\n",
        "# Example\n",
        "#vech = np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9],[10]])\n",
        "#vec = vech2vec(vech)\n",
        "\n",
        "#print(vech)\n",
        "#print(vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG22u6mq9mQT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PD6f9bD9mgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dupMat(n):\n",
        "  \n",
        "  # Make vech of 1:(n(n+1)/2)\n",
        "  vech = np.arange(n*(n+1)/2)\n",
        "  \n",
        "  # Convert to vec\n",
        "  vec = vech2vec(vech)\n",
        "  \n",
        "  # Make D (sparse one hot encoded vec)\n",
        "  D = scipy.sparse.csr_matrix((np.ones(n**2),(np.arange(n**2),np.int64(vec).reshape(vec.shape[0]))))\n",
        "  \n",
        "  return(D)\n",
        "\n",
        "# Example\n",
        "#print(dupMat(3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVrM3CsGSIHL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FR-cwIkSIQJ",
        "colab_type": "code",
        "outputId": "c60940f2-8dcc-4d3a-cace-1ef2d7de8d4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "def invDupMat(n):\n",
        "  \n",
        "  \n",
        "  # Make vech of 1:(n(n+1)/2)\n",
        "  vech = np.arange(n*(n+1)/2)\n",
        "  \n",
        "  # Convert to vec\n",
        "  vec = np.int64(vech2vec(vech))\n",
        "  vec = vec.reshape(vec.shape[0])\n",
        "  \n",
        "  # Work out frequency of each entry\n",
        "  freq = 1/np.bincount(vec)\n",
        "  \n",
        "  # Work out duplication matrix\n",
        "  D = scipy.sparse.csr_matrix((freq[vec],(vec,np.arange(n**2))))\n",
        "  \n",
        "  return(D)\n",
        "\n",
        "# Example\n",
        "print(invDupMat(3))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 0)\t1.0\n",
            "  (1, 1)\t0.5\n",
            "  (1, 3)\t0.5\n",
            "  (2, 2)\t0.5\n",
            "  (2, 6)\t0.5\n",
            "  (3, 4)\t1.0\n",
            "  (4, 5)\t0.5\n",
            "  (4, 7)\t0.5\n",
            "  (5, 8)\t1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2byzJx5Kf5fS",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFCU4gxkf5r8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def blockInverse(matrix, blockSize, numBlocks):\n",
        "\n",
        "  invMatrix = scipy.sparse.csr_matrix((np.array([]), (np.array([]),np.array([]))),shape=matrix.shape)\n",
        "  \n",
        "  # For each level, invert the corresponding block on the diagonal\n",
        "  for i in range(numBlocks):\n",
        "    \n",
        "    # The block is nparams by nparams\n",
        "    blockInds = np.ix_(np.arange(i*blockSize,(i+1)*blockSize),np.arange(i*blockSize,(i+1)*blockSize))\n",
        "    \n",
        "    # Get the block\n",
        "    block = matrix[blockInds]\n",
        "    \n",
        "    # Replace it with it's inverse\n",
        "    invMatrix[blockInds]=scipy.sparse.linalg.inv(block)\n",
        "    \n",
        "  return(invMatrix)\n",
        "\n",
        "# Example - need to have loaded in data first\n",
        "\n",
        "# Get ZtZ just for the first grouping factor\n",
        "firstFactorIndices = np.ix_(np.arange(nlevels[0]*nparams[0]),np.arange(nlevels[0]*nparams[0]))\n",
        "ZtZ_f1 = ZtZ[firstFactorIndices]\n",
        "\n",
        "# Compute the block inverse for ZtZ_f1\n",
        "#t1 = time.time()\n",
        "#ZtZ_f1_inv = blockInverse(matrix=ZtZ_f1, blockSize=nparams[0], numBlocks=nlevels[0])\n",
        "#t2 = time.time()\n",
        "#blockInverse_time = t2-t1\n",
        "\n",
        "# Compare it to the inverse scipy would calculate\n",
        "#t1 = time.time()\n",
        "#ZtZ_f1_inv_sp = scipy.sparse.linalg.inv(ZtZ_f1)\n",
        "#t2 = time.time()\n",
        "#scipyInverse_time = t2-t1\n",
        "\n",
        "#print(blockInverse_time)\n",
        "#print(scipyInverse_time)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BdQ3jh7x71k",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77gBbWIAx8AZ",
        "colab_type": "code",
        "outputId": "30e953c2-85f2-4a59-88b6-745a838e4d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "def recursiveInverse(M, nparams, nlevels):\n",
        "  \n",
        "  # Work out qc\n",
        "  qc = nparams[-1]*nlevels[-1]\n",
        "  \n",
        "  # Make q\n",
        "  q = M.shape[0]\n",
        "  \n",
        "  # Get A, B and C where M=[[A,B],[B',C]]\n",
        "  # A\n",
        "  A_inds = np.ix_(np.arange(0,(q-qc)),np.arange(0,(q-qc)))\n",
        "  A = M[A_inds]\n",
        "  \n",
        "  # B\n",
        "  B_inds = np.ix_(np.arange(0,(q-qc)),np.arange((q-qc),q))\n",
        "  B = M[B_inds].toarray() # B is dense\n",
        "  \n",
        "  # C\n",
        "  C_inds = np.ix_(np.arange((q-qc),q),np.arange((q-qc),q))\n",
        "  C = M[C_inds].toarray() # C is small and now only involved in dense mutliplys\n",
        "  \n",
        "  # Recursive inverse A\n",
        "  if nparams[:-1].shape[0] > 1:\n",
        "    \n",
        "    Ainv = recursiveInverse(A, nparams[:-1], nlevels[:-1]).toarray()\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    #Ainv = blockInverse(A, nparams[0], nlevels[0]) - much slower\n",
        "    Ainv = scipy.sparse.linalg.inv(scipy.sparse.csc_matrix(A)).toarray()\n",
        "  \n",
        "  # Schur complement\n",
        "  S = C-np.matmul(np.matmul(B.transpose(),Ainv),B)\n",
        "  Sinv = np.linalg.inv(S)\n",
        "  \n",
        "  # Top Left Hand Side of inverse\n",
        "  TLHS = Ainv + np.matmul(np.matmul(np.matmul(np.matmul(Ainv,B),Sinv),B.transpose()),Ainv)\n",
        "  \n",
        "  \n",
        "  # Top Right Hand Side of inverse\n",
        "  TRHS = -np.matmul(np.matmul(Ainv,B),Sinv)\n",
        "  \n",
        "  \n",
        "  # Bottom Right Hand Side of inverse\n",
        "  BRHS = Sinv\n",
        "  \n",
        "  # Join together\n",
        "  top = np.hstack((TLHS,TRHS))\n",
        "  bottom = np.hstack((TRHS.transpose(), BRHS))\n",
        "  \n",
        "  # Make Minv\n",
        "  Minv = np.vstack((top, bottom))\n",
        "  \n",
        "  return(Minv)\n",
        "\n",
        "# Example\n",
        "t1 = time.time()\n",
        "ZtZinv_rec = recursiveInverse(ZtZ, nparams, nlevels)\n",
        "t2 = time.time()\n",
        "inv_rec_time = t2-t1\n",
        "\n",
        "t1 = time.time()\n",
        "ZtZinv_sp = scipy.sparse.linalg.inv(scipy.sparse.csc_matrix(ZtZ))\n",
        "t2 = time.time()\n",
        "inv_sp_time = t2-t1\n",
        "\n",
        "t1 = time.time()\n",
        "ZtZinv_np = np.linalg.inv(ZtZ.toarray())\n",
        "t2 = time.time()\n",
        "inv_np_time = t2-t1\n",
        "\n",
        "\n",
        "print('Distance (norm) from identity (scipy)')\n",
        "print(np.linalg.norm(np.matmul(ZtZinv_sp.toarray(),ZtZ.toarray())-np.eye(ZtZ.shape[0])))\n",
        "print('Distance (norm) from identity (numpy)')\n",
        "print(np.linalg.norm(np.matmul(ZtZinv_np,ZtZ.toarray())-np.eye(ZtZ.shape[0])))\n",
        "print('Distance (norm) from identity (rec)')\n",
        "print(np.linalg.norm(np.matmul(ZtZinv_rec,ZtZ.toarray())-np.eye(ZtZ.shape[0])))\n",
        "\n",
        "print(inv_sp_time)\n",
        "print(inv_np_time)\n",
        "print(inv_rec_time)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-6dc87c55f0a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mZtZinv_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecursiveInverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZtZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnlevels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0minv_rec_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-6dc87c55f0a9>\u001b[0m in \u001b[0;36mrecursiveInverse\u001b[0;34m(M, nparams, nlevels)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mB_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mqc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mqc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mB_inds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# B is dense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m# C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'toarray'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPgPFpnOLxdG",
        "colab_type": "text"
      },
      "source": [
        "#### Sum of square residuals\n",
        "\n",
        "The function below calculates the sum of the square residuals, $e^Te$, using the below formula:\n",
        "\n",
        "$$e^Te = (Y-X\\beta)^T(Y-X\\beta)$$ \n",
        "$$=Y^TY - 2Y^TX\\beta + \\beta^T X^TX \\beta$$\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `YtX`: $Y$ transpose multiplied by $X$ ($Y^TX$ in the above notation).\n",
        " - `YtY`: $Y$ transpose multiplied by $Y$ ($Y^TY$ in the above notation).\n",
        " - `XtX`: $X$ transpose multiplied by $X$ ($X^TX$ in the above notation).\n",
        " - `beta`: An estimate of the parameter vector ($\\beta$ in the above notation).\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "\n",
        " - `ete`: The sum of square residuals ($e^Te$ in the above notation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KK0i7TkgNNZD",
        "colab_type": "code",
        "outputId": "ab384094-7544-4b53-e9d2-09df75fdd36e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def ssr(YtX, YtY, XtX, beta):\n",
        "  \n",
        "  # Return the sum of squared residuals\n",
        "  return(YtY - 2*YtX @ beta + beta.transpose() @ XtX @ beta)\n",
        "\n",
        "t1 = time.time()\n",
        "ssr(YtX, YtY, XtX, np.array([[1],[2],[3]]))\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0002415180206298828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO_68uYYxCvf",
        "colab_type": "text"
      },
      "source": [
        "#### Get Factor/Level Indices\n",
        "\n",
        "This function gives the indices of the columns of the $Z$ matrix which correspond to factor $k$ level $j$. \n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `k`: The grouping factor we need the columns of.\n",
        " - `j`: The level of the grouping factor $k$ which we are interested in.\n",
        " - `nlevels`: A vector containing the number of levels for each factor, e.g. `nlevels=[3,4]` would mean the first factor has 3 levels and the second factor has 4 levels.\n",
        " - `nparams`: A vector containing the number of parameters for each factor, e.g. `nlevels=[2,1]` would mean the first factor has 2 parameters and the second factor has 1 parameter.\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `Ikj`: The indices of the columns of $Z$ corresponding to factor $k$ level $j$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSrodNh0zI0_",
        "colab_type": "code",
        "outputId": "ead431c1-1de8-49ad-ed6d-ff9b947f0625",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numba\n",
        "\n",
        "@numba.jit\n",
        "# k and j are both zero indexed\n",
        "def faclev_indices(k, j, nlevels, nparams):\n",
        "  \n",
        "  # Work out the starting point of the indices\n",
        "  start = np.concatenate((np.array([0]), np.cumsum(nlevels*nparams)))[k] + nparams[k]*j\n",
        "  \n",
        "  # work out the end point of the indices\n",
        "  end = start + nparams[k]\n",
        "  \n",
        "  return(np.arange(start, end))\n",
        "\n",
        "t1 = time.time()\n",
        "faclev_indices(0, 1, nlevels, nparams)\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5838181972503662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYv59en2gpt3",
        "colab_type": "code",
        "outputId": "1def8786-43ab-4160-a2e0-22ac7c714588",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t1 = time.time()\n",
        "faclev_indices(0, 1, nlevels, nparams)\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00011229515075683594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xeRsXZBJUGd",
        "colab_type": "text"
      },
      "source": [
        "#### Initial Sigma\n",
        "\n",
        "The function below returns an initial estimate for the Fixed Effects Variance, $\\sigma^2$. The estimator used is based on the suggested OLS estimator in Demidenko (2012) and is given by:\n",
        "\n",
        "$$\\hat{\\sigma}^2_{OLS}=\\frac{1}{n}(Y-X\\beta)^T(Y-X\\beta)$$\n",
        "$$=\\frac{1}{n}e^Te$$\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `ete`: The sum of square residuals ($e^Te$ in the above notation).\n",
        " - `n`: The total number of observations ($n$ in the above notation).\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `sigma2`: The OLS estimate of $\\sigma^2$ ($\\hat{\\sigma}^2_{OLS}$ in the above notation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_STdZ1mNLWbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initSigma2(ete, n):\n",
        "\n",
        "  # Return the OLS estimate of sigma\n",
        "  return(1/n*ete[0,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdtIeA0NNsZl",
        "colab_type": "text"
      },
      "source": [
        "#### Initial D_k\n",
        "\n",
        "The function below returns an initial estimate for the Random Effects Variance matrix for the $k^{th}$ grouping factor, $D_k$. The estimator used is an adaption of the suggested estimator in Demidenko (2012) and is given by:\n",
        "\n",
        "$$vec(\\hat{D}_{k})=\\bigg[\\sum_{j=1}^{l_k}(Z_{(k,j)}^TZ_{(k,j)}) \\otimes (Z_{(k,j)}^TZ_{(k,j)})\\bigg]^{-1}vec\\bigg(\\sum_{j=1}^{l_k}[\\hat{\\sigma}^{-2}_{OLS}Z_{(k,j)}^Tee^TZ_{(k,j)} - Z_{(k,j)}^TZ_{(k,j)}]\\bigg)$$\n",
        "\n",
        "Or:\n",
        "\n",
        "$$\\hat{D}_{k}=matrix\\bigg(\\bigg[\\sum_{j=1}^{l_k}(Z_{(k,j)}^TZ_{(k,j)}) \\otimes (Z_{(k,j)}^TZ_{(k,j)})\\bigg]^{-1}vec\\bigg(\\sum_{j=1}^{l_k}[\\hat{\\sigma}^{-2}_{OLS}Z_{(k,j)}^Tee^TZ_{(k,j)} - Z_{(k,j)}^TZ_{(k,j)}]\\bigg)\\bigg)$$\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `k`: The grouping factor we wish to estimate $D$ for ($k$ in the above notation)\n",
        " - `lk`: The number of levels belonging to grouping factor $k$ ($l_k$ in the above notation).\n",
        " - `ZtZ`: The $Z$ matrix transposed and then multiplied by itself ($Z^TZ$ in the above notation).\n",
        " - `Zte`: The $Z$ matrix transposed and then multiplied by the OLS residuals ($Z^Te=Z^T(Y-X\\beta)$ in the above notation).\n",
        " - `sigma2`: The OLS estimate of $\\sigma^2$ ($\\hat{\\sigma}^2_{OLS}$ in the above notation).\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `Dkest`: The inital estimate of $D_k$ ($\\hat{D}_k$ in the above notation).\n",
        "\n",
        "\n",
        "###CHECK DERIVATION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0J2CFTrNrhq",
        "colab_type": "code",
        "outputId": "2f6da45a-1a92-458d-d4db-30df4e1035fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numba\n",
        "\n",
        "@numba.jit\n",
        "def initDk(k, lk, ZtZ, Zte, sigma2):\n",
        "  \n",
        "  # Initalize D to zeros\n",
        "  invSig2ZteetZminusZtZ = np.zeros((nparams[k],nparams[k]))\n",
        "\n",
        "  \n",
        "  # For each level j we need to add a term\n",
        "  for j in np.arange(nlevels[k]):\n",
        "    \n",
        "    Ikj = faclev_indices(k, j, nlevels, nparams)\n",
        "\n",
        "    # Work out Z_(k, j)'Z_(k, j)\n",
        "    ZkjtZkj = ZtZ[np.ix_(Ikj,Ikj)]\n",
        "    \n",
        "    # Work out Z_(k,j)'e\n",
        "    Zkjte = Zte[Ikj,:]\n",
        "    \n",
        "    if j==0:\n",
        "      \n",
        "      # Add first Z_(k,j)'Z_(k,j) kron Z_(k,j)'Z_(k,j)\n",
        "      ZtZkronZtZ = np.kron(ZkjtZkj,ZkjtZkj.transpose())\n",
        "      \n",
        "      # Add first \\sigma^{-2}Z'ee'Z - Z_(k,j)'Z_(k,j)\n",
        "      invSig2ZteetZminusZtZ = 1/sigma2*(Zkjte @ Zkjte.transpose()) - ZkjtZkj\n",
        "      \n",
        "    else:\n",
        "      \n",
        "      # Add next Z_(k,j)'Z_(k,j) kron Z_(k,j)'Z_(k,j)\n",
        "      ZtZkronZtZ = ZtZkronZtZ + np.kron(ZkjtZkj,ZkjtZkj.transpose())\n",
        "      \n",
        "      # Add next \\sigma^{-2}Z'ee'Z - Z_(k,j)'Z_(k,j)\n",
        "      invSig2ZteetZminusZtZ = invSig2ZteetZminusZtZ + 1/sigma2*(Zkjte @ Zkjte.transpose()) - ZkjtZkj\n",
        "  \n",
        "  # Work out the final term.\n",
        "  Dkest = vec2mat(np.linalg.inv(ZtZkronZtZ) @ mat2vec(invSig2ZteetZminusZtZ)) \n",
        "  \n",
        "  return(Dkest)\n",
        "\n",
        "Zte = ZtY-ZtX @ np.array([[1],[2],[3]])\n",
        "t1 = time.time()\n",
        "initDk(1, nlevels[1], ZtZ, Zte , 1)\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "initDk(1, nlevels[1], ZtZ, Zte , 1)\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9682908058166504\n",
            "0.0013120174407958984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjypr01QTJh5",
        "colab_type": "text"
      },
      "source": [
        "#### Non-negative Definite D\n",
        "\n",
        "The below function takes in a covariance matrix $D$ and finds nearest projection onto the space of non-negative definite matrices $\\mathbb{D}_+$. It uses the following method taken from Demidenko (2012), page 105:\n",
        "\n",
        "If $D$ is non-negative definite and has eigenvalue decomposition $D=P\\Lambda P^T$ it's closest projection into $\\mathbb{D}_+$ is defined by the matrix below:\n",
        "\n",
        "$$\\hat{D}_+ = P\\Lambda_+P'$$\n",
        "\n",
        "Where $\\Lambda_+$ is defined by the elementwise maximum of $\\Lambda$ and 0; i.e. $\\Lambda_{+(i,j)} = max(\\Lambda_{+(i,j)},0)$.\n",
        "\n",
        "Note: This is not to be confused with the generalized inverse of the duplication matrix $\\mathcal{D}^+$.\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `D`: A square symmetric matrix.\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `D_nnd`: The nearest projection of $D$ onto the space of non-negative definite matrices $\\mathbb{D}_+$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2rW_uOBTJ0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makeDnnd(D):\n",
        "  \n",
        "  # Check if we have negative eigenvalues\n",
        "  if not np.all(np.linalg.eigvals(D)>0):\n",
        "  \n",
        "    # If we have negative eigenvalues\n",
        "    eigvals,eigvecs = np.linalg.eigh(D)\n",
        "    \n",
        "    # Work out elementwise max of lambda and 0\n",
        "    lamplus = np.diag(np.maximum(eigvals,0))\n",
        "    \n",
        "    # Work out D+\n",
        "    D_nnd = eigvecs @ lamplus @ np.linalg.inv(eigvecs)\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    # D is already non-negative in this case\n",
        "    D_nnd = D\n",
        "    \n",
        "  return(D_nnd)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70shU6hKlDMR",
        "colab_type": "text"
      },
      "source": [
        "#### Derivative of $l$ with respect to $\\beta$\n",
        "\n",
        "The below function calculates the derivative of the log likelihood with respect to $\\beta$. This is given by the following equation:\n",
        "\n",
        "$$\\frac{\\delta l}{\\delta \\beta} = \\sigma^{-2}X'(I+ZDZ')^{-1}(Y-X\\beta)$$\n",
        "$$ = \\sigma^{-2}X'(I-ZD(I+Z'ZD)^{-1}Z')(Y-X\\beta)$$\n",
        "$$ = \\sigma^{-2}X'(Y-X\\beta)-X'ZD(I+Z'ZD)^{-1}Z'(Y-X\\beta) $$\n",
        "$$ = \\sigma^{-2}X'e-X'ZD(I+Z'ZD)^{-1}Z'e$$\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `XtZ`: The $X$ matrix transposed and then multiplied by Z ($X^TZ$ in the above notation).\n",
        " - `Zte`: The $Z$ matrix transposed and then multiplied by the OLS residuals ($Z^Te=Z^T(Y-X\\beta)$ in the above notation).\n",
        " - `sigma2`: The fixed effects variance ($\\sigma^2$ in the above notation).\n",
        " - `DinvIplusZtZD`: The product $D(I+Z'ZD)^{-1}$.\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `dldb`: The derivative of $l$ with respect to $\\beta$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX6LfLOBlDVn",
        "colab_type": "code",
        "outputId": "1f1d6ac0-5c0b-488b-9616-c84a4b93d83a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "def get_dldB(sigma2, Xte, XtZ, DinvIplusZtZD, Zte):\n",
        "  \n",
        "  # Return the derivative\n",
        "  return(1/sigma2*(Xte - (XtZ @ DinvIplusZtZD @ Zte)))\n",
        "\n",
        "### Test example\n",
        "\n",
        "p = X.shape[1]\n",
        "beta = np.random.randn(p,1)\n",
        "\n",
        "sigma2=1.1\n",
        "D = np.array([])\n",
        "q=Z.shape[1]\n",
        "n=Z.shape[0]\n",
        "for i in np.arange(len(nparams)):\n",
        "  \n",
        "  for j in np.arange(nlevels[i]):\n",
        "    \n",
        "    if i == 0 and j == 0:\n",
        "\n",
        "      D = initDk(i, nlevels[i], ZtZ, Zte, sigma2)\n",
        "\n",
        "    else:\n",
        "\n",
        "      D = scipy.linalg.block_diag(D, initDk(i, nlevels[i], ZtZ, Zte, sigma2))\n",
        "      \n",
        "IplusZtZD = np.eye(q) + ZtZ @ D\n",
        "DinvIplusZtZD = D @ np.linalg.inv(IplusZtZD)\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "dldb1 = (sigma2)**(-1)*(X.transpose() @ np.linalg.inv(np.eye(n) + Z @ D @ Z.transpose()) @ (Y - X @ beta))\n",
        "\n",
        "Xte = XtY- XtX @ beta\n",
        "\n",
        "Zte = ZtY- ZtX @ beta\n",
        "\n",
        "DinvIplusZtZD = D @ np.linalg.inv(np.eye(q) + ZtZ @ D)\n",
        "\n",
        "dldb2 = get_dldB(sigma2, Xte, XtZ, DinvIplusZtZD, Zte)\n",
        "\n",
        "print(dldb1)\n",
        "print(dldb2)\n",
        "\n",
        "\n",
        "print(dldb2-dldb1)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 3)\n",
            "[[2.94935787e-02]\n",
            " [1.54380637e+03]\n",
            " [2.86174943e+03]]\n",
            "[[2.94935786e-02]\n",
            " [1.54380637e+03]\n",
            " [2.86174943e+03]]\n",
            "[[-7.31188235e-11]\n",
            " [-3.93179107e-08]\n",
            " [-2.03641321e-07]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0yUC5yE1qin",
        "colab_type": "text"
      },
      "source": [
        "#### Derivative of $l$ with respect to $D_k$\n",
        "\n",
        "The below function calculates the derivative of the log likelihood with respect to $D_k$, the random effects covariance matrix for factor $k$. This is given by the following equation:\n",
        "\n",
        "$$\\frac{\\delta l}{\\delta D_k} = \\frac{1}{2}\\sum_{j=1}^{l_k}(T_{(k,j)}u)(T_{(k,j)}u)'-\\frac{1}{2}\\sum_{j=1}^{l_k}T_{(k,j)}T_{(k,j)}'$$\n",
        "\n",
        "Where $T_{(i,j)}=Z'_{(i,j)}(I+ZDZ')^{-\\frac{1}{2}}$ and $u=\\sigma^{-1}(I+ZDZ')^{-\\frac{1}{2}}(Y-X\\beta)\\sim N(0,\\mathbb{I})$.\n",
        "\n",
        "$$= \\frac{1}{2\\sigma^2}\\sum_{j=1}^{l_k}Z'_{(k,j)}(I+ZDZ')^{-1}ee'(I+ZDZ')^{-1}Z_{(k,j)} - \\frac{1}{2}\\sum_{j=1}^{l_k}Z'_{(k,j)}(I+ZDZ')^{-1}Z_{(k,j)}$$\n",
        "\n",
        "$$= \\frac{1}{2\\sigma^2}\\sum_{j=1}^{l_k}Z'_{(k,j)}(I-ZD(I+Z'ZD)^{-1}Z')ee'(I-ZD(I+Z'ZD)^{-1}Z')'Z_{(k,j)} - \\frac{1}{2}\\sum_{j=1}^{l_k}Z'_{(k,j)}(I-ZD(I+Z'ZD)^{-1})Z_{(k,j)}$$\n",
        "\n",
        "$$= \\frac{1}{2\\sigma^2}\\sum_{j=1}^{l_k}(Z'_{(k,j)}e-Z'_{(k,j)}ZD(I+Z'ZD)^{-1}Z'e)(Z'_{(k,j)}e-Z'_{(k,j)}ZD(I+Z'ZD)^{-1}Z'e)' - \\frac{1}{2}\\sum_{j=1}^{l_k}Z'_{(k,j)}Z_{(k,j)}-Z'_{(k,j)}ZD(I+Z'ZD)^{-1}Z'Z_{(k,j)}$$\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `k`: The factor we wish to estimate the derivative of the covariance matrix of.\n",
        " - `nlevels`: A vector containing the number of levels for each factor, e.g. `nlevels=[3,4]` would mean the first factor has 3 levels and the second factor has 4 levels.\n",
        " - `nparams`: A vector containing the number of parameters for each factor, e.g. `nlevels=[2,1]` would mean the first factor has 2 parameters and the second factor has 1 parameter.\n",
        " - `ZtZ`: The $Z$ matrix transposed and then multiplied by itself ($Z^TZ$ in the above notation).\n",
        " - `Zte`: The $Z$ matrix transposed and then multiplied by the OLS residuals ($Z^Te=Z^T(Y-X\\beta)$ in the above notation).\n",
        " - `sigma2`: The fixed effects variance ($\\sigma^2$ in the above notation).\n",
        " - `DinvIplusZtZD`: The product $D(I+Z'ZD)^{-1}$.\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `dldD`: The derivative of $l$ with respect to $D_k$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D43Adi61quy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "b6cb54fd-9ce0-4b0c-b408-c71e59dedc03"
      },
      "source": [
        "import numba\n",
        "\n",
        "@numba.jit\n",
        "def get_dlDk(k, nlevels, nparams, ZtZ, Zte, sigma2, DinvIplusZtZD):\n",
        "\n",
        "  # Initalize the derivative to zeros\n",
        "  dldDk = np.zeros((nparams[k],nparams[k]))\n",
        "\n",
        "  # For each level j we need to add a term\n",
        "  for j in np.arange(nlevels[k]):\n",
        "\n",
        "    # Get the indices for the kth factor jth level\n",
        "    Ikj = faclev_indices(k, j, nlevels, nparams)\n",
        "\n",
        "    # Get (the kj^th columns of Z)^T multiplied by Z\n",
        "    Z_kjtZ = ZtZ[Ikj,:]\n",
        "    Z_kjte = Zte[Ikj,:]\n",
        "\n",
        "    # Get the first term of the derivative\n",
        "    invZ_kjtVinve = Z_kjte - (Z_kjtZ @ DinvIplusZtZD @ Zte)\n",
        "    firstterm = 1/sigma2 * (invZ_kjtVinve @ invZ_kjtVinve.transpose())\n",
        "    \n",
        "    # Get (the kj^th columns of Z)^T multiplied by (the kj^th columns of Z)\n",
        "    Z_kjtZ_kj = ZtZ[np.ix_(Ikj,Ikj)]\n",
        "    secondterm = Z_kjtZ_kj - (Z_kjtZ @ DinvIplusZtZD @ Z_kjtZ.transpose())\n",
        "\n",
        "    if j == 0:\n",
        "      print('TuutTt (1)')\n",
        "      print(firstterm)\n",
        "\n",
        "      print('TTt (1)')\n",
        "      print(secondterm)\n",
        "      \n",
        "    if j == 0:\n",
        "      \n",
        "      # Start a running sum over j\n",
        "      dldDk = firstterm - secondterm\n",
        "      \n",
        "    else:\n",
        "    \n",
        "      # Add these to the running sum\n",
        "      dldDk = dldDk + firstterm - secondterm\n",
        "\n",
        "  # Halve the sum (the coefficient of a half was not included in the above)\n",
        "  dldDk = dldDk/2\n",
        "\n",
        "  # Store it in the dictionary\n",
        "  return(dldDk)\n",
        "\n",
        "IplusZtZD = np.eye(q) + ZtZ @ D\n",
        "DinvIplusZtZD = D @ np.linalg.inv(IplusZtZD)\n",
        "\n",
        "Zte = Z.transpose() @ (Y - X @ beta)\n",
        "\n",
        "k=0\n",
        "t1 = time.time()\n",
        "dldDk = get_dlDk(k, nlevels, nparams, ZtZ, Zte, sigma2, DinvIplusZtZD)\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "t1 = time.time()\n",
        "dldDk = get_dlDk(k, nlevels, nparams, ZtZ, Zte, sigma2, DinvIplusZtZD)\n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "### Check against alternative formula\n",
        "\n",
        "invhalf = np.linalg.inv(scipy.linalg.sqrtm(np.eye(n) + Z @ D @ Z.transpose()))\n",
        "for j in np.arange(nlevels[k]):\n",
        "  \n",
        "  # Get the indices for the kth factor jth level\n",
        "  Ikj = faclev_indices(k, j, nlevels, nparams)\n",
        "    \n",
        "  T = Z[:, Ikj].transpose() @  invhalf\n",
        "  \n",
        "  u = invhalf @ (Y- X @ beta)/sigma2\n",
        "  \n",
        "  Tu = T @ u\n",
        "  \n",
        "  TTt = T @ T.transpose()\n",
        "  \n",
        "  TuutTt = Tu @ Tu.transpose()\n",
        "  if j == 0:\n",
        "    print('TuutTt (2)')\n",
        "    print(TuutTt)\n",
        "\n",
        "    print('TTt (2)')\n",
        "    print(TTt)\n",
        "      \n",
        "  if j == 0:\n",
        "    \n",
        "    runningsum = 0.5*(-TTt+TuutTt)\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    runningsum = runningsum + 0.5*(-TTt+TuutTt)\n",
        "    \n",
        "print(runningsum-dldDk)\n",
        "print(runningsum)\n",
        "print(dldDk)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TuutTt (1)\n",
            "[[2.77960373e-06 5.07123505e-05]\n",
            " [5.07123505e-05 9.25219113e-04]]\n",
            "TTt (1)\n",
            "[[4.73184785e-05 3.98295727e-05]\n",
            " [4.39206121e-04 2.51096910e-04]]\n",
            "0.9802548885345459\n",
            "TuutTt (1)\n",
            "[[2.77960373e-06 5.07123505e-05]\n",
            " [5.07123505e-05 9.25219113e-04]]\n",
            "TTt (1)\n",
            "[[4.73184785e-05 3.98295727e-05]\n",
            " [4.39206121e-04 2.51096910e-04]]\n",
            "0.0027773380279541016\n",
            "TuutTt (2)\n",
            "[[ 8.21069484e-13+7.02471156e-27j -1.29707872e-12-2.78734935e-26j]\n",
            " [-1.29707872e-12-2.78734935e-26j  2.04905096e-12+7.05351250e-26j]]\n",
            "TTt (2)\n",
            "[[ 1.02450199e-07-7.79262954e-29j -1.57342830e-07+1.08198142e-28j]\n",
            " [-1.57342830e-07+1.08198142e-28j  2.50227632e-07-1.48654973e-28j]]\n",
            "[[-1.07881081+1.25454418e-25j -0.04829759-1.90797382e-25j]\n",
            " [ 0.00246961-1.90797382e-25j -0.00447064+2.90051599e-25j]]\n",
            "[[-1.02450014e-06+1.25454418e-25j  1.57342537e-06-1.90797382e-25j]\n",
            " [ 1.57342537e-06-1.90797382e-25j -2.50227170e-06+2.90051599e-25j]]\n",
            "[[ 1.07880979  0.04829916]\n",
            " [-0.00246804  0.00446814]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW-p5bOy4K-u",
        "colab_type": "text"
      },
      "source": [
        "#### Covariance of $\\frac{\\delta l}{\\delta \\text{vech}(D_{k_1})}$ and $\\frac{\\delta l}{\\delta \\text{vech}(D_{k_2})}$\n",
        "\n",
        "The below function calculates the covariance between the derivative of the log likelihood with respect to $\\text{vech}(D_{k_1})$ and the derivative with respect to $\\text{vech}(D_{k_2})$.\n",
        "\n",
        "$$\\text{cov}\\bigg(\\frac{\\delta l(\\theta | y)}{\\delta \\text{vech}(D_{k_2})},\\frac{\\delta l(\\theta | y)}{\\delta \\text{vech}(D_{k_2})}\\bigg)=\\frac{1}{2}\\mathcal{D}_{k_1}^+\\sum_{j=1}^{l_{k_2}}\\sum_{i=1}^{l_{k_1}}(R_{(k_1,k_2,i,j)}\\otimes R_{(k_1,k_2, i,j)}')\\mathcal{D}_{k_2}^{+'}$$\n",
        "\n",
        "\n",
        "\n",
        "Where $R_{(k_1,k_2,i,j)}=Z_{(k_1,i)}'(I+ZDZ')^{-1}Z_{(k_2,j)}=Z_{(k_1,i)}'Z_{(k_2,j)} - Z_{(k_1,i)}'ZD(I+Z'ZD)^{-1}Z_{(k_2,j)}$.\n",
        "\n",
        "----\n",
        "\n",
        "This function takes the following inputs:\n",
        "\n",
        "----\n",
        "\n",
        " - `k1`: The number of the first factor ($k_1$ in the above notation).\n",
        " - `k2`: The number of the second factor ($k_2$ in the above notation).\n",
        " - `nlevels`: A vector containing the number of levels for each factor, e.g. `nlevels=[3,4]` would mean the first factor has 3 levels and the second factor has 4 levels.\n",
        " - `nparams`: A vector containing the number of parameters for each factor, e.g. `nlevels=[2,1]` would mean the first factor has 2 parameters and the second factor has 1 parameter.\n",
        " - `ZtZ`: $Z$ transpose multiplied by $Z$.\n",
        " - `DinvIplusZtZD`: $D(I+Z'ZD)^{-1}$ in the above notation.\n",
        " - `invDupMatdict`: A dictionary of inverse duplication matrices such that `invDupMatdict[k]` = $\\mathcal{D}_k^+$\n",
        " \n",
        "----\n",
        "\n",
        "It returns as outputs:\n",
        "\n",
        "----\n",
        "\n",
        "- `covdldDk1dldk2`: The covariance between the derivative of the log likelihood with respect to $\\text{vech}(D_{k_1})$ and the derivative with respect to $\\text{vech}(D_{k_2})$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoAsQQtM4LLs",
        "colab_type": "code",
        "outputId": "7ba5f0da-1df4-4bb7-9c78-280e2f91fa49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "import numba\n",
        "\n",
        "@numba.jit\n",
        "def get_covdldDk1Dk2(k1, k2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict):\n",
        "  \n",
        "  # Sum of R_(k1, k2, i, j) kron R_(k1, k2, i, j) over i and j \n",
        "  for i in np.arange(nlevels[k1]):\n",
        "\n",
        "    for j in np.arange(nlevels[k2]):\n",
        "      \n",
        "      # Get the indices for the k1th factor jth level\n",
        "      Ik1i = faclev_indices(k1, i, nlevels, nparams)\n",
        "      Ik2j = faclev_indices(k2, j, nlevels, nparams)\n",
        "\n",
        "      # Work out R_(k1, k2, i, j)\n",
        "      Rk1k2ij = ZtZ[np.ix_(Ik1i,Ik2j)] - (ZtZ[Ik1i,:] @ DinvIplusZtZD @ ZtZ[:,Ik2j])\n",
        "\n",
        "      # Work out Rk1k2ij kron Rk1k2ij\n",
        "      RkRt = np.kron(Rk1k2ij,Rk1k2ij.transpose())\n",
        "      \n",
        "      # Add together\n",
        "      if (i == 0) and (j == 0):\n",
        "      \n",
        "        RkRtSum = RkRt\n",
        "      \n",
        "      else:\n",
        "        \n",
        "        RkRtSum = RkRtSum + RkRt\n",
        "\n",
        "  # Multiply by duplication matrices and save\n",
        "  covdldDk1dldk2 = 1/2 * invDupMatdict[k1] @ RkRtSum @ invDupMatdict[k2].transpose()\n",
        "\n",
        "  # Return the result\n",
        "  return(covdldDk1dldk2)\n",
        "\n",
        "\n",
        "# Example\n",
        "\n",
        "invDupMatdict = dict()\n",
        "for i in np.arange(len(nparams)):\n",
        "  \n",
        "  invDupMatdict[i] = invDupMat(nparams[i])\n",
        "  \n",
        "t1 = time.time()\n",
        "examplecov = get_covdldDk1Dk2(0, 0, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict)\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)\n",
        "print(examplecov)\n",
        "k1 = 0\n",
        "k2 = 0\n",
        "\n",
        "t1 = time.time()\n",
        "examplecov = get_covdldDk1Dk2(k1, k2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict)\n",
        "t2 = time.time()\n",
        "\n",
        "print(t2-t1)\n",
        "print(examplecov)\n",
        "\n",
        "print(invDupMatdict[k1])\n",
        "\n",
        "# Check against alternative expression\n",
        "Ztmp = Z.toarray()\n",
        "\n",
        "IplusZDZt = np.eye(n) + Z @ D @ Z.transpose()\n",
        "\n",
        "invhalfIplusZDZt = scipy.linalg.sqrtm(np.linalg.inv(IplusZDZt))\n",
        "\n",
        "for j in np.arange(nlevels[k1]):\n",
        "  \n",
        "  Ikj = faclev_indices(k1, j, nlevels, nparams)\n",
        "\n",
        "  Tkj = Z[:,Ikj].transpose() @ invhalfIplusZDZt \n",
        "  \n",
        "  if j == 0:\n",
        "    \n",
        "    sumTkT = np.kron(Tkj,Tkj)\n",
        "  \n",
        "  else:\n",
        "    \n",
        "    sumTkT = np.kron(Tkj,Tkj) + sumTkT\n",
        "\n",
        "    \n",
        "for j in np.arange(nlevels[k2]):\n",
        "  \n",
        "  Ikj = faclev_indices(k2, j, nlevels, nparams)\n",
        "\n",
        "  Tkj = Z[:,Ikj].transpose() @ invhalfIplusZDZt \n",
        "  \n",
        "  Tkjt = Tkj.transpose()\n",
        "  \n",
        "  if j == 0:\n",
        "    \n",
        "    sumTtkTt = np.kron(Tkjt,Tkjt)\n",
        "  \n",
        "  else:\n",
        "    \n",
        "    sumTtkTt = np.kron(Tkjt,Tkjt) + sumTtkTt\n",
        "\n",
        "print(1/2 * invDupMatdict[k1] @ sumTkT @ sumTtkTt @ invDupMatdict[k2].transpose())\n",
        "print(np.abs(1/2 * invDupMatdict[k1] @ sumTkT @ sumTtkTt @ invDupMatdict[k2].transpose() - examplecov)/examplecov)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7326769828796387\n",
            "[[ 4.22883636 -1.6982862   0.68202593]\n",
            " [-1.6982862   1.42262307 -0.86874182]\n",
            " [ 0.68202593 -0.86874182  1.13303168]]\n",
            "0.030488967895507812\n",
            "[[ 4.22883636 -1.6982862   0.68202593]\n",
            " [-1.6982862   1.42262307 -0.86874182]\n",
            " [ 0.68202593 -0.86874182  1.13303168]]\n",
            "  (0, 0)\t1.0\n",
            "  (1, 1)\t0.5\n",
            "  (1, 2)\t0.5\n",
            "  (2, 3)\t1.0\n",
            "[[ 4.22883636-1.82549870e-16j -1.6982862 -1.80826392e-15j\n",
            "   0.68202593+1.48182523e-15j]\n",
            " [-1.6982862 -1.80826392e-15j  1.42262307-5.47461474e-17j\n",
            "  -0.86874182-3.20110565e-16j]\n",
            " [ 0.68202593+1.48182523e-15j -0.86874182-3.20110565e-16j\n",
            "   1.13303168-1.74267793e-15j]]\n",
            "[[ 6.46259343e-13 -1.72807392e-12  2.98069713e-10]\n",
            " [-1.73003512e-12  7.52098738e-11 -6.48913098e-12]\n",
            " [ 2.98069713e-10 -6.49283708e-12  7.12758629e-13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWnudhK-03e8",
        "colab_type": "code",
        "outputId": "fa1b8e44-79f0-47e1-9816-949265e98240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Number of factors r\n",
        "r = len(nlevels)\n",
        "n=Z.shape[0]\n",
        "\n",
        "q = np.sum(np.dot(nparams,nlevels))\n",
        "\n",
        "# Initial estimates\n",
        "p = XtX.shape[0]\n",
        "beta = np.ones((p,1))\n",
        "\n",
        "# Work out e'e\n",
        "ete = ssr(YtX, YtY, XtX, beta)\n",
        "\n",
        "# Initial sigma2\n",
        "sigma2 = initSigma2(ete, n)\n",
        "Ddict = dict()\n",
        "Zte = ZtY - (ZtX @ beta)\n",
        "# For each factor, factor k, work out sum Z_kj'Z_kj kron Z_kj'Z_kj\n",
        "for k in np.arange(len(nparams)):\n",
        "  \n",
        "  Dktmp = initDk(k, nlevels[k], ZtZ, Zte, sigma2)\n",
        "  #if not np.all(np.linalg.eigvals(Dktmp)>0):\n",
        "  #\n",
        "  #  eigvals,eigvecs = np.linalg.eigh(Dktmp)\n",
        "  #  \n",
        "  #  lamplus = np.diag(np.maximum(eigvals,0))\n",
        "  #  \n",
        "  #  Dktmp = eigvecs @ lamplus @ np.linalg.inv(eigvecs)\n",
        "    \n",
        "  Ddict[k] = Dktmp\n",
        "  \n",
        "  print(Ddict[k])\n",
        "\n",
        "D = np.array([])\n",
        "for i in np.arange(len(nparams)):\n",
        "  \n",
        "  for j in np.arange(nlevels[i]):\n",
        "    \n",
        "    if i == 0 and j == 0:\n",
        "\n",
        "      D = Ddict[i]\n",
        "\n",
        "    else:\n",
        "\n",
        "      D = scipy.linalg.block_diag(D, Ddict[i])\n",
        "      \n",
        "imshow(D, \\\n",
        "       interpolation='nearest', vmin=-5, vmax=5, aspect='auto')\n",
        "\n",
        "invDupMatdict = dict()\n",
        "for i in np.arange(len(nparams)):\n",
        "  \n",
        "  invDupMatdict[i] = invDupMat(nparams[i])\n",
        "  \n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "for z in np.arange(1000):\n",
        "\n",
        "  #print('sigma2')\n",
        "  #print(sigma2)\n",
        "  #print('beta')\n",
        "  #print(beta)\n",
        "  #print('D0')\n",
        "  #print(Ddict[0])\n",
        "  #print('D1')\n",
        "  #print(Ddict[1])\n",
        "  \n",
        "  Xte = XtY - (XtX @ beta)\n",
        "  #print('Xte')\n",
        "  #print(Xte)\n",
        "  \n",
        "  Zte = ZtY - (ZtX @ beta)\n",
        "  #print('Zte')\n",
        "  #print(Zte)\n",
        "  \n",
        "  IplusZtZD = np.eye(q) + ZtZ @ D\n",
        "  #print('I + ZtZD')\n",
        "  #print(IplusZtZD)\n",
        "  \n",
        "  DinvIplusZtZD = D @ np.linalg.inv(IplusZtZD)\n",
        "  #print('D(I + ZtZD)^-1')\n",
        "  #print(DinvIplusZtZD)\n",
        "\n",
        "  ete = ssr(YtX, YtY, XtX, beta)\n",
        "\n",
        "  dldB = get_dldB(sigma2, Xte, XtZ, DinvIplusZtZD, Zte)\n",
        "  #print('dl/dB')\n",
        "  #print(dldB)\n",
        "\n",
        "  dldsigma2 = -n/(2*sigma2)  + 1/(2*(sigma2**2))*(ete - (Zte.transpose() @ DinvIplusZtZD @ Zte))\n",
        "  #print('dl/dsigma^2')\n",
        "  #print(dldsigma2)\n",
        "\n",
        "  dldDdict = dict()\n",
        "  # For each factor, factor k, work out dl/dD_k\n",
        "  for k in np.arange(len(nparams)):\n",
        "    \n",
        "    # Initalize the derivative to zeros\n",
        "    dldDk = np.zeros((nparams[k],nparams[k]))\n",
        "\n",
        "    # For each level j we need to add a term\n",
        "    for j in np.arange(nlevels[k]):\n",
        "\n",
        "      # Get the indices for the kth factor jth level\n",
        "      Ikj = faclev_indices(k, j, nlevels, nparams)\n",
        "\n",
        "      # Get (the kj^th columns of Z)^T multiplied by Z\n",
        "      Z_kjtZ = ZtZ[Ikj,:]\n",
        "      Z_kjte = Zte[Ikj,:]\n",
        "\n",
        "      # Get the first term of the derivative\n",
        "      invZ_kjtVinve = Z_kjte - (Z_kjtZ @ DinvIplusZtZD @ Zte)\n",
        "      firstterm = 1/sigma2 * (invZ_kjtVinve @ invZ_kjtVinve.transpose())\n",
        "\n",
        "      # Get (the kj^th columns of Z)^T multiplied by (the kj^th columns of Z)\n",
        "      Z_kjtZ_kj = ZtZ[np.ix_(Ikj,Ikj)]\n",
        "      secondterm = Z_kjtZ_kj - (Z_kjtZ @ DinvIplusZtZD @ Z_kjtZ.transpose())\n",
        "\n",
        "      # Add these to the running sum\n",
        "      dldDk = dldDk + firstterm - secondterm\n",
        "\n",
        "    # Halve the sum (the coefficient of a half was not included in the above)\n",
        "    dldDk = dldDk/2\n",
        "\n",
        "    # Store it in the dictionary\n",
        "    dldDdict[k] = dldDk\n",
        "\n",
        "  #print('dl/dD1')\n",
        "  #print(dldDdict[0])\n",
        "  #print('dl/dD2')\n",
        "  #print(dldDdict[1])\n",
        "  #print('dl/dD2')\n",
        "  #print(dldDdict[1])\n",
        "  \n",
        "  # Work out covariance of dl/dbeta\n",
        "  covdldB = (1/sigma2)*(XtX - (XtZ @ DinvIplusZtZD @ ZtX))\n",
        "\n",
        "  # Work out covariance of dl/dsigma2\n",
        "  covdldsigma2 = n/(2*(sigma2**2))\n",
        "  \n",
        "  covdldDdict = dict()\n",
        "  # For each pair of factors, factor k1 and k2, work out dl/dD_k\n",
        "  for k1 in np.arange(len(nparams)):\n",
        "\n",
        "    for k2 in np.arange(k1+1):\n",
        "\n",
        "      # Multiply by duplication matrices and save\n",
        "      covdldDdict[str(k1) + str(k2)] = get_covdldDk1Dk2(k1, k2, nlevels, nparams, ZtZ, DinvIplusZtZD, invDupMatdict)\n",
        "\n",
        "  covdldDdldsigmadict = dict()\n",
        "\n",
        "  # For each factor, factor k, work out cov(dl/dD_k, dl/dsigma)\n",
        "  for k in np.arange(len(nparams)):\n",
        "\n",
        "    # Sum of R_(k, j) over j\n",
        "    RkSum = np.zeros(nparams[k],nparams[k])\n",
        "\n",
        "    for j in np.arange(nlevels[k]):\n",
        "\n",
        "      # Get the indices for the kth factor jth level\n",
        "      Ikj = faclev_indices(k, j, nlevels, nparams)\n",
        "\n",
        "      # Work out R_(k, j)\n",
        "      Rkj = ZtZ[np.ix_(Ikj,Ikj)] - (ZtZ[Ikj,:] @ DinvIplusZtZD @ ZtZ[:,Ikj])\n",
        "\n",
        "      # Add together\n",
        "      RkSum = RkSum + Rkj\n",
        "\n",
        "    # Multiply by duplication matrices and save\n",
        "    covdldDdldsigmadict[k] = 1/(2*sigma2) * invDupMatdict[k] @ mat2vec(RkSum)\n",
        "\n",
        "  # Work out the total number of paramateres\n",
        "  tnp = np.int32(p + 1 + np.sum(nparams*(nparams+1)/2))\n",
        "\n",
        "  # Indices for submatrics corresponding to Dks\n",
        "  FishIndsDk = np.int32(np.cumsum(nparams*(nparams+1)/2) + p + 1)\n",
        "  FishIndsDk = np.insert(FishIndsDk,0,p+1)\n",
        "\n",
        "  # Construct the Fisher Information matrix\n",
        "  FisherInfoMat = np.zeros((tnp,tnp))\n",
        "\n",
        "  # Add dl/dbeta covariance\n",
        "  FisherInfoMat[np.ix_(np.arange(p),np.arange(p))] = covdldB\n",
        "\n",
        "  # Add dl/dsigma2 covariance\n",
        "  #print(covdldsigma2)\n",
        "  FisherInfoMat[p,p] = covdldsigma2\n",
        "\n",
        "  # Add dl/dsigma2 dl/dD covariance\n",
        "  for k in np.arange(len(nparams)):\n",
        "\n",
        "    # Work out number of covariance parameters estimated\n",
        "    qk = np.int32(nparams[k]*(nparams[k]+1)/2)\n",
        "\n",
        "    # Assign to the relevant block\n",
        "    FisherInfoMat[p, FishIndsDk[k]:FishIndsDk[k+1]] = covdldDdldsigmadict[k].reshape(qk)\n",
        "    FisherInfoMat[FishIndsDk[k]:FishIndsDk[k+1],p] = covdldDdldsigmadict[k].reshape(qk)\n",
        "\n",
        "  # Add dl/dD covariance\n",
        "  for k1 in np.arange(len(nparams)):\n",
        "\n",
        "    for k2 in np.arange(k1+1):\n",
        "\n",
        "      IndsDk1 = np.arange(FishIndsDk[k1],FishIndsDk[k1+1])\n",
        "      IndsDk2 = np.arange(FishIndsDk[k2],FishIndsDk[k2+1])\n",
        "      FisherInfoMat[np.ix_(IndsDk1, IndsDk2)] = covdldDdict[str(k1) + str(k2)]\n",
        "      FisherInfoMat[np.ix_(IndsDk2, IndsDk1)] = covdldDdict[str(k1) + str(k2)].transpose()\n",
        "\n",
        "  paramVector = np.concatenate((beta, np.array([[sigma2]])))\n",
        "  derivVector = np.concatenate((dldB, dldsigma2))\n",
        "\n",
        "  for k in np.arange(len(nparams)):\n",
        "\n",
        "    paramVector = np.concatenate((paramVector, mat2vech(Ddict[k])))\n",
        "    derivVector = np.concatenate((derivVector, mat2vech(dldDdict[k])))\n",
        "\n",
        "  # Iterate step\n",
        "  #paramVectorPrev = paramVector\n",
        "  #print('Infomat')\n",
        "  #print(FisherInfoMat)\n",
        "  #print('Infomat Inv')\n",
        "  #print(np.linalg.inv(FisherInfoMat))\n",
        "  #print('Paramvec')\n",
        "  #print(paramVector)\n",
        "  paramVector = paramVector + (np.linalg.inv(FisherInfoMat) @ derivVector)\n",
        "  #print(paramVector)\n",
        "  beta = paramVector[0:p]\n",
        "  sigma2 = paramVector[p:(p+1)][0,0]\n",
        "\n",
        "  for k in np.arange(len(nparams)):\n",
        "\n",
        "    # Work out number of covariance parameters estimated\n",
        "    qk = np.int32(nparams[k]*(nparams[k]+1)/2)\n",
        "    \n",
        "    # Work out the new estimate of D_k\n",
        "    #print(paramVector)\n",
        "    Dktmp = vech2mat(paramVector[(p + 1 + k*qk):(p + 1 + (k+1)*qk)])\n",
        "    \n",
        "    # Check if D_k is pd; if not project it to a pd space\n",
        "    #print('Before')\n",
        "    #print(Dktmp)\n",
        "    if not np.all(np.linalg.eigvals(Dktmp)>0):\n",
        "    \n",
        "      eigvals,eigvecs = np.linalg.eigh(Dktmp)\n",
        "     \n",
        "      lamplus = np.diag(np.maximum(eigvals,0))\n",
        "      \n",
        "      Dktmp = eigvecs @ lamplus @ np.linalg.inv(eigvecs)\n",
        "    \n",
        "    #print('After')\n",
        "    #print(Dktmp)\n",
        "    Ddict[k] = Dktmp \n",
        "  #print('paramvec')\n",
        "  #print(paramVector)\n",
        "  print(z)\n",
        "  \n",
        "  for i in np.arange(len(nparams)):\n",
        "\n",
        "    for j in np.arange(nlevels[i]):\n",
        "      \n",
        "\n",
        "      if i == 0 and j == 0:\n",
        "\n",
        "        D = Ddict[i]\n",
        "\n",
        "      else:\n",
        "\n",
        "        D = scipy.linalg.block_diag(D, Ddict[i])\n",
        "        \n",
        "  #print(np.all(np.linalg.eigvals(Ddict[0])>0))\n",
        "  #print(np.all(np.linalg.eigvals(Ddict[1])>0))\n",
        "     \n",
        "   \n",
        "  #print('D')\n",
        "  #print(D)\n",
        "  #print('D0')\n",
        "  #print(Ddict[0])\n",
        "  #print('D1')\n",
        "  #print(Ddict[1])\n",
        "  \n",
        "t2 = time.time()\n",
        "print(t2-t1)\n",
        "\n",
        "print(FisherInfoMat)\n",
        "imshow(FisherInfoMat, \\\n",
        "       interpolation='nearest', vmin=-5, vmax=5, aspect='auto')\n",
        "\n",
        "plt.colorbar()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.01849284  0.0007871 ]\n",
            " [ 0.0007871   0.00225612]]\n",
            "[[ 5.33495946e-03 -1.35970642e-04]\n",
            " [-1.35970642e-04 -1.64807395e-05]]\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n",
            "500\n",
            "501\n",
            "502\n",
            "503\n",
            "504\n",
            "505\n",
            "506\n",
            "507\n",
            "508\n",
            "509\n",
            "510\n",
            "511\n",
            "512\n",
            "513\n",
            "514\n",
            "515\n",
            "516\n",
            "517\n",
            "518\n",
            "519\n",
            "520\n",
            "521\n",
            "522\n",
            "523\n",
            "524\n",
            "525\n",
            "526\n",
            "527\n",
            "528\n",
            "529\n",
            "530\n",
            "531\n",
            "532\n",
            "533\n",
            "534\n",
            "535\n",
            "536\n",
            "537\n",
            "538\n",
            "539\n",
            "540\n",
            "541\n",
            "542\n",
            "543\n",
            "544\n",
            "545\n",
            "546\n",
            "547\n",
            "548\n",
            "549\n",
            "550\n",
            "551\n",
            "552\n",
            "553\n",
            "554\n",
            "555\n",
            "556\n",
            "557\n",
            "558\n",
            "559\n",
            "560\n",
            "561\n",
            "562\n",
            "563\n",
            "564\n",
            "565\n",
            "566\n",
            "567\n",
            "568\n",
            "569\n",
            "570\n",
            "571\n",
            "572\n",
            "573\n",
            "574\n",
            "575\n",
            "576\n",
            "577\n",
            "578\n",
            "579\n",
            "580\n",
            "581\n",
            "582\n",
            "583\n",
            "584\n",
            "585\n",
            "586\n",
            "587\n",
            "588\n",
            "589\n",
            "590\n",
            "591\n",
            "592\n",
            "593\n",
            "594\n",
            "595\n",
            "596\n",
            "597\n",
            "598\n",
            "599\n",
            "600\n",
            "601\n",
            "602\n",
            "603\n",
            "604\n",
            "605\n",
            "606\n",
            "607\n",
            "608\n",
            "609\n",
            "610\n",
            "611\n",
            "612\n",
            "613\n",
            "614\n",
            "615\n",
            "616\n",
            "617\n",
            "618\n",
            "619\n",
            "620\n",
            "621\n",
            "622\n",
            "623\n",
            "624\n",
            "625\n",
            "626\n",
            "627\n",
            "628\n",
            "629\n",
            "630\n",
            "631\n",
            "632\n",
            "633\n",
            "634\n",
            "635\n",
            "636\n",
            "637\n",
            "638\n",
            "639\n",
            "640\n",
            "641\n",
            "642\n",
            "643\n",
            "644\n",
            "645\n",
            "646\n",
            "647\n",
            "648\n",
            "649\n",
            "650\n",
            "651\n",
            "652\n",
            "653\n",
            "654\n",
            "655\n",
            "656\n",
            "657\n",
            "658\n",
            "659\n",
            "660\n",
            "661\n",
            "662\n",
            "663\n",
            "664\n",
            "665\n",
            "666\n",
            "667\n",
            "668\n",
            "669\n",
            "670\n",
            "671\n",
            "672\n",
            "673\n",
            "674\n",
            "675\n",
            "676\n",
            "677\n",
            "678\n",
            "679\n",
            "680\n",
            "681\n",
            "682\n",
            "683\n",
            "684\n",
            "685\n",
            "686\n",
            "687\n",
            "688\n",
            "689\n",
            "690\n",
            "691\n",
            "692\n",
            "693\n",
            "694\n",
            "695\n",
            "696\n",
            "697\n",
            "698\n",
            "699\n",
            "700\n",
            "701\n",
            "702\n",
            "703\n",
            "704\n",
            "705\n",
            "706\n",
            "707\n",
            "708\n",
            "709\n",
            "710\n",
            "711\n",
            "712\n",
            "713\n",
            "714\n",
            "715\n",
            "716\n",
            "717\n",
            "718\n",
            "719\n",
            "720\n",
            "721\n",
            "722\n",
            "723\n",
            "724\n",
            "725\n",
            "726\n",
            "727\n",
            "728\n",
            "729\n",
            "730\n",
            "731\n",
            "732\n",
            "733\n",
            "734\n",
            "735\n",
            "736\n",
            "737\n",
            "738\n",
            "739\n",
            "740\n",
            "741\n",
            "742\n",
            "743\n",
            "744\n",
            "745\n",
            "746\n",
            "747\n",
            "748\n",
            "749\n",
            "750\n",
            "751\n",
            "752\n",
            "753\n",
            "754\n",
            "755\n",
            "756\n",
            "757\n",
            "758\n",
            "759\n",
            "760\n",
            "761\n",
            "762\n",
            "763\n",
            "764\n",
            "765\n",
            "766\n",
            "767\n",
            "768\n",
            "769\n",
            "770\n",
            "771\n",
            "772\n",
            "773\n",
            "774\n",
            "775\n",
            "776\n",
            "777\n",
            "778\n",
            "779\n",
            "780\n",
            "781\n",
            "782\n",
            "783\n",
            "784\n",
            "785\n",
            "786\n",
            "787\n",
            "788\n",
            "789\n",
            "790\n",
            "791\n",
            "792\n",
            "793\n",
            "794\n",
            "795\n",
            "796\n",
            "797\n",
            "798\n",
            "799\n",
            "800\n",
            "801\n",
            "802\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "847\n",
            "848\n",
            "849\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "854\n",
            "855\n",
            "856\n",
            "857\n",
            "858\n",
            "859\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "864\n",
            "865\n",
            "866\n",
            "867\n",
            "868\n",
            "869\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n",
            "906\n",
            "907\n",
            "908\n",
            "909\n",
            "910\n",
            "911\n",
            "912\n",
            "913\n",
            "914\n",
            "915\n",
            "916\n",
            "917\n",
            "918\n",
            "919\n",
            "920\n",
            "921\n",
            "922\n",
            "923\n",
            "924\n",
            "925\n",
            "926\n",
            "927\n",
            "928\n",
            "929\n",
            "930\n",
            "931\n",
            "932\n",
            "933\n",
            "934\n",
            "935\n",
            "936\n",
            "937\n",
            "938\n",
            "939\n",
            "940\n",
            "941\n",
            "942\n",
            "943\n",
            "944\n",
            "945\n",
            "946\n",
            "947\n",
            "948\n",
            "949\n",
            "950\n",
            "951\n",
            "952\n",
            "953\n",
            "954\n",
            "955\n",
            "956\n",
            "957\n",
            "958\n",
            "959\n",
            "960\n",
            "961\n",
            "962\n",
            "963\n",
            "964\n",
            "965\n",
            "966\n",
            "967\n",
            "968\n",
            "969\n",
            "970\n",
            "971\n",
            "972\n",
            "973\n",
            "974\n",
            "975\n",
            "976\n",
            "977\n",
            "978\n",
            "979\n",
            "980\n",
            "981\n",
            "982\n",
            "983\n",
            "984\n",
            "985\n",
            "986\n",
            "987\n",
            "988\n",
            "989\n",
            "990\n",
            "991\n",
            "992\n",
            "993\n",
            "994\n",
            "995\n",
            "996\n",
            "997\n",
            "998\n",
            "999\n",
            "69.0921540260315\n",
            "[[ 1.66908985e-01 -7.51687397e-04 -1.45330523e-03  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-7.36705979e-04  1.06428916e+03 -8.47376880e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [-1.46960138e-03 -8.47376914e+00  9.90701099e+02  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
            "   0.00000000e+00  0.00000000e+00]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  5.20020062e+02\n",
            "   7.55441451e+00 -5.58098223e-03  2.20518586e-06  8.39454331e-02\n",
            "  -9.15295739e-02  9.99610292e-02]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  7.55441451e+00\n",
            "   5.76966527e+00 -4.26589132e-03  3.15399437e-06  2.23223585e-04\n",
            "  -1.21315023e-04 -2.99515701e-07]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -5.58098223e-03\n",
            "  -4.26589132e-03  2.45846768e-06 -1.29603534e-09 -1.21315023e-04\n",
            "   6.63232478e-05 -2.39611431e-07]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  2.20518586e-06\n",
            "   3.15399437e-06 -1.29603534e-09  4.59823530e-10 -2.99515701e-07\n",
            "  -2.39611431e-07  2.86999420e-08]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  8.39454331e-02\n",
            "   2.23223585e-04 -1.21315023e-04 -2.99515701e-07  4.51711338e-03\n",
            "  -4.92523304e-03  5.37024943e-03]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -9.15295739e-02\n",
            "  -1.21315023e-04  6.63232478e-05 -2.39611431e-07 -4.92523304e-03\n",
            "   5.37459323e-03 -5.86493383e-03]\n",
            " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  9.99610292e-02\n",
            "  -2.99515701e-07 -2.39611431e-07  2.86999420e-08  5.37024943e-03\n",
            "  -5.86493383e-03  6.40519507e-03]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f9c90995160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAD8CAYAAAAylrwMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpiSHkObQ7yN",
        "colab_type": "code",
        "outputId": "bb1fea5d-8bd2-4af4-a42d-01f288dab164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(beta)\n",
        "\n",
        "print(RFXVar_REst)\n",
        "\n",
        "print(sigma2)\n",
        "print(Ddict[0])\n",
        "print(Ddict[1])\n",
        "\n",
        "\n",
        "print(\"U estimates (R)\")\n",
        "print(pd.read_csv('/Data/BLMM-testdata/estd_b.csv',header=None).values.reshape(23,2))\n",
        "print(\"U estimates (FS)\")\n",
        "print((DinvIplusZtZD @ Zte).reshape(23,2))\n",
        "print(\"U true\")\n",
        "print(pd.read_csv('/Data/BLMM-testdata/true_b.csv',header=None).values.reshape(23,2))\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.4489861 ]\n",
            " [ 1.98321808]\n",
            " [ 3.03160277]]\n",
            "[[ 1.24022707  0.36034323  0.          0.        ]\n",
            " [ 0.36034323  5.0719078   0.          0.        ]\n",
            " [ 0.          0.         20.68631165 -0.79595202]\n",
            " [ 0.          0.         -0.79595202  0.21015464]]\n",
            "0.9805644975626752\n",
            "[[9.21302983e+00 1.07183148e+04]\n",
            " [1.07183148e+04 1.44544623e+07]]\n",
            "[[30685651.25683375 28115374.41908455]\n",
            " [28115374.41908455 25760409.10203517]]\n",
            "U estimates (R)\n",
            "[[-0.16266309 -4.21724427]\n",
            " [ 1.41643004  1.41243783]\n",
            " [ 1.59527575 -1.58921871]\n",
            " [ 1.57314783  0.40497904]\n",
            " [ 1.29727291  0.93796984]\n",
            " [-1.20537013  2.19715236]\n",
            " [-0.62177368 -1.1845146 ]\n",
            " [-0.8982196  -1.34761407]\n",
            " [ 0.2105669   2.5381855 ]\n",
            " [-0.57561587 -3.43679857]\n",
            " [ 1.33808317  0.10724134]\n",
            " [-1.20676845 -2.43712662]\n",
            " [ 0.64262693  1.33629341]\n",
            " [-0.9916963  -0.08043681]\n",
            " [ 1.44782818  2.19618068]\n",
            " [-1.25815704  4.3074814 ]\n",
            " [ 0.27424557  0.87149959]\n",
            " [-0.78704685 -3.16062475]\n",
            " [-1.48916827 -0.24116661]\n",
            " [-0.47444214  3.13847411]\n",
            " [ 1.80633411  0.64368738]\n",
            " [ 2.06756827 -0.15742136]\n",
            " [-7.37272861  0.43752657]]\n",
            "U estimates (FS)\n",
            "[[-0.16423572 -4.2172833 ]\n",
            " [ 1.40958345  1.41244802]\n",
            " [ 1.59202639 -1.58921936]\n",
            " [ 1.56759907  0.4049791 ]\n",
            " [ 1.29105096  0.93797462]\n",
            " [-1.21471848  2.19718857]\n",
            " [-0.62700951 -1.18452018]\n",
            " [-0.90345115 -1.34763605]\n",
            " [ 0.20165507  2.53821782]\n",
            " [-0.57770854 -3.43690408]\n",
            " [ 1.33266732  0.10722052]\n",
            " [-1.21087663 -2.43714218]\n",
            " [ 0.63546299  1.33631236]\n",
            " [-0.99849198 -0.08043422]\n",
            " [ 1.44019436  2.19620981]\n",
            " [-1.27012905  4.30753785]\n",
            " [ 0.26743029  0.87151037]\n",
            " [-0.79023962 -3.16065719]\n",
            " [-1.49604369 -0.24117106]\n",
            " [-0.48456932  3.13848745]\n",
            " [ 3.30395628  0.64381571]\n",
            " [ 3.5647     -0.15742468]\n",
            " [-5.87536137  0.43755245]]\n",
            "U true\n",
            "[[-0.19301143 -4.22666242]\n",
            " [ 1.43735476  1.40883489]\n",
            " [ 1.34711832 -1.58788242]\n",
            " [ 1.81825209  0.3910735 ]\n",
            " [ 1.25654173  0.94063103]\n",
            " [-1.22775617  2.19293973]\n",
            " [-0.79408731 -1.19281546]\n",
            " [-0.9898057  -1.35221872]\n",
            " [-0.03319243  2.53178969]\n",
            " [-0.65604937 -3.43139032]\n",
            " [ 1.42910277  0.11018046]\n",
            " [-0.96244844 -2.43071144]\n",
            " [ 0.70088294  1.33487455]\n",
            " [-1.3137399  -0.07784482]\n",
            " [ 1.45666816  2.19521647]\n",
            " [-1.3663195   4.30629966]\n",
            " [ 0.22757187  0.87208539]\n",
            " [-0.89571743 -3.14622337]\n",
            " [-1.51292639 -0.23242295]\n",
            " [-0.5588196   3.15054584]\n",
            " [ 1.85205881  0.64080503]\n",
            " [ 2.10133112 -0.1570577 ]\n",
            " [-7.27154738  0.44280999]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhQP_ZYStIDL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM_nXUHfJEd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.min(np.abs(np.linalg.inv(FisherInfoMat)[np.linalg.inv(FisherInfoMat)!=0])))\n",
        "print(paramVector)\n",
        "print(derivVector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uyderceEM3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 0\n",
        "j = 3\n",
        "Z2 = Z.toarray()\n",
        "e = Y - X @ beta\n",
        "print(np.sum(np.sum(np.abs(Z2[:,faclev_indices(k, j, nlevels, nparams)].transpose() @ Z2 - ZtZ[faclev_indices(k, j, nlevels, nparams), :]))))\n",
        "\n",
        "print(np.sum(np.sum(np.abs(Z2[:,faclev_indices(k, j, nlevels, nparams)].transpose() @ e - Zte[faclev_indices(k, j, nlevels, nparams), :]))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhOHZ6F2DU5e",
        "colab_type": "text"
      },
      "source": [
        "## Calculating the Information matrix\n",
        "\n",
        "Fisher scoring requires the calculation of the information matrix, $\\mathcal{I}$. This is done using the method outlined in [Demidenko 2013](https://www.wiley.com/en-us/Mixed+Models%3A+Theory+and+Applications+with+R%2C+2nd+Edition-p-9781118091579) section 3.3.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVtC2_vLtsY2",
        "colab_type": "text"
      },
      "source": [
        "### Fisher Information Matrix function\n",
        "\n",
        "This function calculates the Fisher Information matrix.\n",
        "\n",
        "---\n",
        "\n",
        "The following inputs are required for this function:\n",
        "\n",
        "---\n",
        "\n",
        " - **ZtX**: Z transpose multiplied by X.\n",
        " - **ZtY**: Z transpose multiplied by Y.\n",
        " - **XtX**: X transpose multiplied by X.\n",
        " - **ZtZ**: Z transpose multiplied by Z.\n",
        " - **XtY**: X transpose multiplied by Y.\n",
        " - **YtX**: Y transpose multiplied by X.\n",
        " - **YtZ**: Y transpose multiplied by Z.\n",
        " - **XtZ**: X transpose multiplied by Z.\n",
        " - **YtY**: Y transpose multiplied by Y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9Ty4TMRUjS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)\n",
        "Xtmp = np.random.randn(10,9)\n",
        "\n",
        "XkX = np.kron(Xtmp,Xtmp)\n",
        "\n",
        "#print(XkX.shape[0]^2)\n",
        "\n",
        "#print(XkX.shape[0]**2)\n",
        "#print(np.power(XkX.shape[0],2))\n",
        "\n",
        "R = (np.arange(XkX.shape[0]))\n",
        "#print(R)\n",
        "\n",
        "#print(R.shape)\n",
        "Rt = mat2vec(vec2mat(R).transpose())\n",
        "\n",
        "perm = np.argsort(Rt.reshape(Rt.shape[0]))\n",
        "\n",
        "K = np.eye(R.shape[0],R.shape[0])\n",
        "K=K[:,perm]\n",
        "\n",
        "#print(perm)\n",
        "\n",
        "imshow(K, \\\n",
        "   interpolation='nearest', aspect='auto',vmax=2,vmin=-1)\n",
        "plt.colorbar()\n",
        "\n",
        "#print(K @ R.reshape(R.shape[0],1) - Rt.reshape(R.shape[0],1))\n",
        "\n",
        "R = (np.arange(XkX.shape[1]))\n",
        "#print(R)\n",
        "\n",
        "#print(R.shape)\n",
        "Rt = mat2vec(vec2mat(R).transpose())\n",
        "\n",
        "perm = np.argsort(Rt.reshape(Rt.shape[0]))\n",
        "\n",
        "K2 = np.eye(R.shape[0],R.shape[0])\n",
        "K2=K2[:,perm]\n",
        "\n",
        "#print(perm)\n",
        "\n",
        "imshow(K2, \\\n",
        "   interpolation='nearest', aspect='auto',vmax=2,vmin=-1)\n",
        "plt.colorbar()\n",
        "\n",
        "#print(K2 @ R.reshape(R.shape[0],1) - Rt.reshape(R.shape[0],1))\n",
        "\n",
        "N = (K + np.eye(K.shape[0]))/2\n",
        "N2 = (K2 + np.eye(K2.shape[0]))/2\n",
        "\n",
        "#print(K.shape)\n",
        "#print(K2.shape)\n",
        "#print(XkX.shape)\n",
        "print((N @ XkX))\n",
        "#print((N @ XkX).shape)\n",
        "#print((XkX @ N2).shape)\n",
        "\n",
        "print((XkX @ N2)-(N @ XkX))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fRUGMZ96yKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtmp = np.random.randn(100,100)\n",
        "\n",
        "imshow(np.kron(Xtmp,Xtmp)[1:100,1:100], \\\n",
        "   interpolation='nearest', aspect='auto',vmax=2,vmin=-1)\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr7WPsyU7LZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imshow(np.kron(Xtmp[1:10,1:10],Xtmp[1:10,1:10]), \\\n",
        "   interpolation='nearest', aspect='auto',vmax=2,vmin=-1)\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Nazpuh-A5vx",
        "colab_type": "text"
      },
      "source": [
        "## Scaling up the computation (Multiple voxels)\n",
        "\n",
        "This section has several implemented ideas for scaling up the computation to compute several similar models at once. For simplicity it is assumed here that X and Z are the same across voxels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enYnjHWXBVmO",
        "colab_type": "text"
      },
      "source": [
        "### Toy data for Neighbouring voxel\n",
        "\n",
        "To assess the potential of the following ideas a toy data example is created below. The idea behind this is that we wish to calculate both the model in the example used in the previous sections and, additionally a similar model from a neighbouring voxel (variables related to the neighbouring voxel will have postfix `_n`). \n",
        "\n",
        "This is not a rigourous test, but just a toy example to see if we can lower the computational time in an example vaguely similar to what we may expect in reality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzUVeNWeDLmy",
        "colab_type": "text"
      },
      "source": [
        "#### Beta vector\n",
        "\n",
        "In a neighbouring voxel, we would expect similar Beta values but not necessarily the same. To simulate this, I have added some normal noise with variance, 1/2, to the original beta values to obtain a new beta value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hKzWuueBbeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Given a beta vector this function makes a beta \n",
        "# vector for the neighbouring voxel\n",
        "def beta_n(beta):\n",
        "  return(beta + np.random.randn(beta.shape[0],1)/np.sqrt(2))\n",
        "\n",
        "# Example\n",
        "beta_True_n = beta_n(beta_True)\n",
        "  \n",
        "# print betas for comparison\n",
        "print(\"Beta for voxel 1\")\n",
        "print(beta_True)\n",
        "print(\"Beta for voxel 2\")\n",
        "print(beta_True_n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTQFQbRLDKmq",
        "colab_type": "text"
      },
      "source": [
        "#### b vector\n",
        "\n",
        "In a neighbouring voxel, we may also expect similar b values. To simulate this, I have added some normal noise with variance, 1/2, to the original b values to obtain a new b value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsyjopBUFNt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Given a b vector this function makes a b\n",
        "# vector for the neighbouring voxel\n",
        "def b_n(b):\n",
        "  return(b + np.random.randn(b.shape[0],1)/np.sqrt(2))\n",
        "\n",
        "# Example\n",
        "b_True_n = b_n(b_True)\n",
        "  \n",
        "# print bs for comparison\n",
        "print(\"b for voxel 1 (first 5 elements)\")\n",
        "print(b_True[1:5])\n",
        "print(\"b for voxel 2 (first 5 elements)\")\n",
        "print(b_True_n[1:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFb5eO8jBWSf",
        "colab_type": "text"
      },
      "source": [
        " #### Y vector (New response)\n",
        " \n",
        "I now generate a new response vector with the new beta and b values for the neighbouring voxel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V59rDqEGU5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Neighbouring voxels response vector\n",
        "Y_n = np.matmul(X,beta_True_n)+Z*b_True_n+np.random.randn(1000,1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1fjCdxgH3aV",
        "colab_type": "text"
      },
      "source": [
        "### Product Matrices\n",
        "\n",
        "All products of matrices are calculated beforehand as it is both more computationally efficient and also similar to the setting we are interested in. For the neighbouring voxel only those involving the Y vector (response) need be recalculated as X and Z have not changed between voxel in this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wnx7aj6OH3tA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Z tranpose Y_n\n",
        "ZtY_n=cvxopt.spmatrix.trans(Z)*Y_n\n",
        "\n",
        "# X tranpose Y_n\n",
        "XtY_n=cvxopt.matrix.trans(X)*Y_n\n",
        "\n",
        "# Y_n tranpose X\n",
        "YtX_n=cvxopt.matrix.trans(Y_n)*X\n",
        "\n",
        "# Y_n transpose Z\n",
        "YtZ_n=cvxopt.matrix.trans(Y_n)*Z\n",
        "\n",
        "# Y_n tranpose Y_n\n",
        "YtY_n=cvxopt.matrix.trans(Y_n)*Y_n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqbOzGU-It3f",
        "colab_type": "text"
      },
      "source": [
        "#### Time efficiency\n",
        "\n",
        "What is really important here is not the estimate values (assuming they are correct), but the time taken to do this for both voxels. In the below, the two voxels are estimated 100 times twice, once reusing the estmate from the first voxel in estimating the second, and once computing the voxels completely seperately.\n",
        "\n",
        "**Conclusion:** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OM3CTjNJXp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KowcFHBSSAIa",
        "colab_type": "text"
      },
      "source": [
        "#### Idea 1: Broadcast everything\n",
        "\n",
        "The title for this idea speaks for itself. The `scipy` library does not allow for broadcasting of sparse matrices, however the libraries `sparse` and `dask` supposedly do (little documentation is available for this however). If these can be used for broadcasting then this algorithm might be reasonably streamlinable for large numbers of voxels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkCJOA2DkdNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}